import requests
import re
from typing import List, Dict
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes
from openai import OpenAI
from datetime import datetime

TELEGRAM_TOKEN = "7918970741:AAEk6UNuzfRk0zU4TLv_dn6Xh0I_F9lbLVg"
client = OpenAI(
    base_url="http://80.209.242.40:8000/v1",
    api_key="dummy-key"
)

DIRECTIONS = {
    "–≠–ø–∏–≥–µ–Ω–µ—Ç–∏–∫–∞": ["epigenetic", "methylation", "histone"],
    "–ú–µ—Ç–∞–±–æ–ª–∏–∑–º": ["metabolism", "mitochondria", "NAD", "AMPK"],
    "–ò–º–º—É–Ω–æ–ª–æ–≥–∏—è": ["immunology", "immune", "inflammation", "cytokine"],
    "–°–µ–Ω–µ—Å—Ü–µ–Ω—Ü–∏—è": ["senescence", "senescent", "p16", "SASP"],
    "–¢–µ–ª–æ–º–µ—Ä—ã": ["telomere", "telomerase"],
    "Aging": ["aging", "ageing", "longevity", "lifespan"]
}

def fetch_pubmed_articles(query: str, max_results: int = 10) -> List[Dict]:
    url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
    params = {"db": "pubmed", "term": query, "retmax": max_results, "retmode": "json"}
    resp = requests.get(url, params=params).json()
    ids = resp.get("esearchresult", {}).get("idlist", [])
    if not ids:
        return []
    url2 = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    params2 = {"db": "pubmed", "id": ",".join(ids), "retmode": "xml"}
    xml = requests.get(url2, params=params2).text
    titles = re.findall(r"<ArticleTitle>(.*?)</ArticleTitle>", xml, re.DOTALL)
    abstracts = re.findall(r"<AbstractText.*?>(.*?)</AbstractText>", xml, re.DOTALL)
    dois = re.findall(r'<ELocationID EIdType="doi" ValidYN="Y">(.*?)</ELocationID>', xml)
    articles = []
    for i, pmid in enumerate(ids):
        title = titles[i] if i < len(titles) else ""
        abstract = abstracts[i] if i < len(abstracts) else ""
        link = f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
        doi = dois[i] if i < len(dois) else ""
        articles.append({"pmid": pmid, "title": title, "abstract": abstract, "link": link, "doi": doi})
    return articles

def classify_directions(text: str) -> List[str]:
    found = []
    text = text.lower()
    for dir_name, keywords in DIRECTIONS.items():
        for kw in keywords:
            if kw in text:
                found.append(dir_name)
                break
    return found or ["Aging"]

def aggregate_by_direction(articles: List[Dict]) -> Dict[str, Dict]:
    result = {}
    for art in articles:
        dirs = classify_directions(art['title'] + ' ' + art['abstract'])
        for d in dirs:
            if d not in result:
                result[d] = {"support": 0, "articles": []}
            result[d]["support"] += 1
            result[d]["articles"].append(art)
    return result

def confidence_word(n_support: int) -> str:
    if n_support >= 7:
        return "–í—ã—Å–æ–∫–∞—è (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Ü–µ–Ω–∑–∏—Ä—É–µ–º—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π)"
    elif n_support >= 4:
        return "–°—Ä–µ–¥–Ω—è—è (–µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π –≤ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ)"
    else:
        return "–ù–∏–∑–∫–∞—è (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π)"

def gpt_generate_summary_ru(direction: str, article: Dict, n_support: int) -> str:
    prompt = (
        f"–ù–∞–ø–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∫–æ—Ä–æ—Ç–∫–æ–µ (–¥–æ 150 —Å–ª–æ–≤) –æ–ø–∏—Å–∞–Ω–∏–µ —Å—É—Ç–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ '{direction}' –Ω–∞ –±–∞–∑–µ —ç—Ç–æ–π —Å—Ç–∞—Ç—å–∏ ('{article['title']}') –∏ –µ—ë –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏."
        f"–ò—Å–ø–æ–ª—å–∑—É–π –Ω–∞—É—á–Ω–æ-–ø–æ–ø—É–ª—è—Ä–Ω—ã–π —Å—Ç–∏–ª—å, –Ω–µ –∫–æ–ø–∏—Ä—É–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é, –∞ –æ–±–æ–±—â–∏ –≥–ª–∞–≤–Ω–æ–µ."
        f"\n–í —Å—Ç–∞—Ç—å–µ: {article['abstract']}\n"
        f"–ù–∞–π–¥–µ–Ω–æ supporting-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {n_support}."
    )
    response = client.chat.completions.create(
        model="llama-3.3-70b-instruct",
        messages=[
            {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω–µ, –≤—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–µ—à—å –ø–æ-—Ä—É—Å—Å–∫–∏."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=220,
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()

def gpt_extract_keywords_ru(title: str, abstract: str, n: int = 7) -> str:
    prompt = (
        f"–í—ã–¥–µ–ª–∏ 5‚Äì7 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–ª–∏ —Ñ—Ä–∞–∑ –ø–æ —ç—Ç–æ–π –Ω–∞—É—á–Ω–æ–π —Å—Ç–∞—Ç—å–µ –∏ –µ—ë –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏, –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∏—Ö —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é. –ù–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç.\n"
        f"–ù–∞–∑–≤–∞–Ω–∏–µ: {title}\n–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {abstract}"
    )
    response = client.chat.completions.create(
        model="llama-3.3-70b-instruct",
        messages=[
            {"role": "system", "content": "–¢—ã –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫, –≤—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=60,
        temperature=0.4,
    )
    return response.choices[0].message.content.strip()

def get_supporting_articles(articles: List[Dict], exclude_pmid: str, limit: int = 3) -> List[Dict]:
    result = []
    for art in articles:
        if art['pmid'] == exclude_pmid:
            continuegir
        result.append({"title": art['title'], "link": art['link']})
        if len(result) >= limit:
            break
    return result

def format_answer(
    top_dir: str, date_str: str, article: Dict, doi: str,
    keywords: str, summary: str, n_support: int, supporting_list: List[Dict],
    confidence: str, consensus: str
) -> str:
    supporting_examples = ""
    for art in supporting_list:
        supporting_examples += f"{art['title']} üîó ({art['link']})\n"
    if not supporting_examples:
        supporting_examples = "–ù–µ—Ç –¥—Ä—É–≥–∏—Ö supporting-—Å—Ç–∞—Ç–µ–π\n"

    doi_part = f" (DOI: {doi})" if doi else ""
    return (
        f"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è –∑–∞–¥–∞—á–∞ üìã: {top_dir}\n"
        f"–î–∞—Ç–∞ üìÖ: {date_str}\n\n"
        f"–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ üìÑ: {article['title']}\n"
        f"–°—Å—ã–ª–∫–∞ üîó: {article['link']}{doi_part}\n"
        f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ üè∑Ô∏è: {keywords}\n\n"
        f"–ö–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ ‚ÑπÔ∏è:\n{summary}\n\n"
        f"–û—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ç—å–∏ üìä:\n"
        f"–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ üìö: {n_support}\n"
        f"–ü—Ä–∏–º–µ—Ä—ã:\n{supporting_examples}"
        f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ‚úÖ: {confidence}\n"
        f"–ö–æ–Ω—Å–µ–Ω—Å—É—Å ü§ù: {consensus}\n"
        f"–¢–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞ üóÑÔ∏è: PubMed\n"
        f"–ö–∞—á–µ—Å—Ç–≤–æ ‚≠ê: –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ—Ü–µ–Ω–∑–∏—Ä—É–µ–º—ã–µ –∏–∑–¥–∞–Ω–∏—è"
    )

async def task(update: Update, context: ContextTypes.DEFAULT_TYPE):
    articles = fetch_pubmed_articles("aging OR senescence OR epigenetic OR metabolism", max_results=15)
    if not articles:
        await update.message.reply_text("–°–µ–≥–æ–¥–Ω—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π.")
        return
    agg = aggregate_by_git initdirection(articles)
    if not agg:
        await update.message.reply_text("–ù–µ—Ç –∑–∞–¥–∞—á –ø–æ –∫–ª—é—á–µ–≤—ã–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º —Å–µ–≥–æ–¥–Ω—è.")
        return
    top_dir = max(agg, key=lambda d: agg[d]['support'])
    entry = agg[top_dir]
    best_article = entry["articles"][0]
    keywords = gpt_extract_keywords_ru(best_article['title'], best_article['abstract'])
    summary = gpt_generate_summary_ru(top_dir, best_article, entry["support"])
    confidence = confidence_word(entry["support"])
    consensus = "–î–∞ (–¥–∞–Ω–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Å–æ–≥–ª–∞—Å—É—é—Ç—Å—è)" if entry["support"] > 1 else "–ù–µ—Ç (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π)"
    now = datetime.now().strftime("%d.%m.%Y")
    supporting_articles = get_supporting_articles(entry["articles"], best_article['pmid'], limit=3)
    answer = format_answer(
        top_dir, now, best_article, best_article.get('doi', ''),
        keywords, summary, entry['support'], supporting_articles,
        confidence, consensus
    )
    await update.message.reply_text(answer)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø LongevityBionixBot.\n"
        "–Ø –µ–∂–µ–¥–Ω–µ–≤–Ω–æ –Ω–∞—Ö–æ–∂—É –¥–ª—è —Ç–µ–±—è –∫–ª—é—á–µ–≤—É—é –∑–∞–¥–∞—á—É –≤ –Ω–∞—É–∫–µ –æ –¥–æ–ª–≥–æ–ª–µ—Ç–∏–∏: —Å—Ç–∞—Ç—å—è, —Å—Å—ã–ª–∫–∞, –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä –∏ –æ—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏.\n"
        "–í–≤–µ–¥–∏ /task, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –∑–∞–¥–∞—á—É –¥–Ω—è."
    )

def run_bot():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("task", task))
    import asyncio
    asyncio.run(app.run_polling())

if __name__ == "__main__":
    run_bot()
