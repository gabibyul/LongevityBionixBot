import requests
import re
from typing import List, Dict
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes
from openai import OpenAI
from datetime import datetime

# ==== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–∫–µ–Ω–∞ –∏ –º–æ–¥–µ–ª–∏ ====
TELEGRAM_TOKEN = "TOKEM"
client = OpenAI(
    base_url="TOKEN",
    api_key="dummy-key"
)

def fetch_pubmed_articles(query: str, max_results: int = 10) -> List[Dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—å–∏ –∏–∑ PubMed –ø–æ –ø–æ–∏—Å–∫–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É."""
    url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
    params = {"db": "pubmed", "term": query, "retmax": max_results, "retmode": "json"}
    resp = requests.get(url, params=params).json()
    ids = resp.get("esearchresult", {}).get("idlist", [])
    if not ids:
        return []
    url2 = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    params2 = {"db": "pubmed", "id": ",".join(ids), "retmode": "xml"}
    xml = requests.get(url2, params=params2).text
    titles = re.findall(r"<ArticleTitle>(.*?)</ArticleTitle>", xml, re.DOTALL)
    abstracts = re.findall(r"<AbstractText.*?>(.*?)</AbstractText>", xml, re.DOTALL)
    dois = re.findall(r'<ELocationID EIdType="doi" ValidYN="Y">(.*?)</ELocationID>', xml)
    articles = []
    for i, pmid in enumerate(ids):
        title = titles[i] if i < len(titles) else ""
        abstract = abstracts[i] if i < len(abstracts) else ""
        doi = dois[i] if i < len(dois) else ""
        link = f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
        articles.append({"pmid": pmid, "title": title, "abstract": abstract, "link": link, "doi": doi})
    return articles

def is_human_study(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Å—Ç–∞—Ç—å—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ —á–µ–ª–æ–≤–µ–∫–µ, –∞ –Ω–µ –æ –∂–∏–≤–æ—Ç–Ω—ã—Ö, —Ä–∞—Å—Ç–µ–Ω–∏—è—Ö –∏ –¥—Ä.
    """
    must_have = ["human", "homo sapiens", "—á–µ–ª–æ–≤–µ–∫", "patients", "elderly", "aged"]
    not_have = [
        "mouse", "mice", "rat", "rats", "plant", "plants", "arabidopsis",
        "grape", "yeast", "drosophila", "zebrafish", "caenorhabditis", "c. elegans",
        "vine", "rice", "corn", "wheat", "fly", "flies"
    ]
    text = text.lower()
    return any(mh in text for mh in must_have) and not any(nh in text for nh in not_have)

def gpt_extract_question_and_answer(article: Dict) -> Dict[str, str]:
    """
    LLM –≤—ã–¥–µ–ª—è–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –ø–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ (–≤—Å–µ–≥–¥–∞ –∏–∑ –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–∏),
    —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –Ω–µ—Å–æ—Å—Ç—ã–∫–æ–≤–æ–∫.
    """
    prompt = (
        f"–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω–µ –∏ —Å—Ç–∞—Ä–µ–Ω–∏—é —á–µ–ª–æ–≤–µ–∫–∞. –ü—Ä–æ—á–∏—Ç–∞–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é: \"{article['abstract']}\". "
        f"1. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ–¥–∏–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ—à–∞–ª–∏ –∞–≤—Ç–æ—Ä—ã —Å—Ç–∞—Ç—å–∏ (—Å—Ç—Ä–æ–≥–æ –ø–æ —Å—É—Ç–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏!). "
        f"2. –î–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –Ω–∞—É—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ—Ä–æ—Å 1, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—à–ª–∏ –∞–≤—Ç–æ—Ä—ã, —Å—Ç—Ä–æ–≥–æ –ø–æ —Ç–µ–∫—Å—Ç—É —Å—Ç–∞—Ç—å–∏.\n"
        f"–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n–í–æ–ø—Ä–æ—Å: ...\n–û—Ç–≤–µ—Ç: ...\n"
        f"–ï—Å–ª–∏ —Å—Ç–∞—Ç—å—è –Ω–µ –ø–æ —Å—Ç–∞—Ä–µ–Ω–∏—é —á–µ–ª–æ–≤–µ–∫–∞ ‚Äî –Ω–∞–ø–∏—à–∏: \"–°—Ç–∞—Ç—å—è –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–¥–∞—á–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏–∏\"."
    )
    response = client.chat.completions.create(
        model="llama-3.3-70b-instruct",
        messages=[{"role": "system", "content": "–¢—ã –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —ç–∫—Å–ø–µ—Ä—Ç."},
                  {"role": "user", "content": prompt}],
        max_tokens=220,
        temperature=0.2,
    )
    text = response.choices[0].message.content.strip()
    # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    q = r"–í–æ–ø—Ä–æ—Å:(.*)"
    a = r"–û—Ç–≤–µ—Ç:(.*)"
    question = re.search(q, text)
    answer = re.search(a, text)
    return {
        "question": question.group(1).strip() if question else "",
        "answer": answer.group(1).strip() if answer else ""
    }

def gpt_extract_keywords_ru(article: Dict) -> str:
    """LLM –≤—ã–¥–µ–ª—è–µ—Ç 5-7 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤/—Ñ—Ä–∞–∑ –Ω–∞ —Ä—É—Å—Å–∫–æ–º."""
    prompt = (
        f"–í—ã–¥–µ–ª–∏ 5‚Äì7 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–ª–∏ —Ñ—Ä–∞–∑ –ø–æ —Å—Ç–∞—Ç—å–µ –∏ –µ—ë –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∏—Ö —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é. –ë–µ–∑ –ª–∏—à–Ω–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.\n"
        f"–ù–∞–∑–≤–∞–Ω–∏–µ: {article['title']}\n–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {article['abstract']}"
    )
    response = client.chat.completions.create(
        model="llama-3.3-70b-instruct",
        messages=[{"role": "system", "content": "–¢—ã –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫."},
                  {"role": "user", "content": prompt}],
        max_tokens=40,
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()

def get_supporting_articles(articles: List[Dict], exclude_pmid: str, limit: int = 3) -> List[Dict]:
    """–í—ã–±–∏—Ä–∞–µ—Ç supporting-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî –¥–æ 3 –¥—Ä—É–≥–∏—Ö —Å—Ç–∞—Ç–µ–π –ø–æ —Ç–µ–º–µ."""
    return [art for art in articles if art['pmid'] != exclude_pmid][:limit]

def confidence_word(n_support: int) -> str:
    if n_support >= 7:
        return "–í—ã—Å–æ–∫–∞—è (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Ü–µ–Ω–∑–∏—Ä—É–µ–º—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π)"
    elif n_support >= 4:
        return "–°—Ä–µ–¥–Ω—è—è (–µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π)"
    else:
        return "–ù–∏–∑–∫–∞—è (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π)"

async def task(update: Update, context: ContextTypes.DEFAULT_TYPE):
    now = datetime.now().strftime("%d.%m.%Y")
    query = "aging AND (lifespan OR longevity OR senescence OR anti-aging) AND (human OR homo sapiens)"
    articles = fetch_pubmed_articles(query, max_results=15)
    # –ù–∞–π–¥—ë–º –ø–µ—Ä–≤—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —Å—Ç–∞—Ç—å—é
    main = None
    for article in articles:
        if is_human_study(article['title'] + ' ' + article['abstract']):
            main = article
            break
    if not main:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —Å—Ç–∞—Ç—å—é –ø–æ –¥–æ–ª–≥–æ–ª–µ—Ç–∏—é —á–µ–ª–æ–≤–µ–∫–∞.")
        return

    # Supporting-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–¥–æ 3)
    supporting = get_supporting_articles(articles, main['pmid'])
    n_support = 1 + len(supporting)
    confidence = confidence_word(n_support)
    consensus = "–î–∞ (–¥–∞–Ω–Ω—ã–µ —Å–æ–≥–ª–∞—Å—É—é—Ç—Å—è)" if n_support > 1 else "–ù–µ—Ç (—Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏—è)"

    # LLM: –í–æ–ø—Ä–æ—Å + –û—Ç–≤–µ—Ç (–µ–¥–∏–Ω—ã–π prompt), –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    qa = gpt_extract_question_and_answer(main)
    keywords = gpt_extract_keywords_ru(main)

    supporting_lines = ""
    for art in supporting:
        supporting_lines += f"{art['title']} üîó ({art['link']})\n"

    doi_part = f" (DOI: {main['doi']})" if main['doi'] else ""
    answer = (
        f"–†–µ—à–∞–µ–º—ã–π –≤–æ–ø—Ä–æ—Å:üìã {qa['question']}\n"
        f"–î–∞—Ç–∞ üìÖ: {now}\n\n"
        f"–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ üìÑ: {main['title']}\n"
        f"–°—Å—ã–ª–∫–∞ üîó: {main['link']}{doi_part}\n"
        f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ üè∑Ô∏è: {keywords}\n\n"
        f"–ö–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ ‚ÑπÔ∏è:\n{qa['answer']}\n\n"
        f"–û—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ç—å–∏ üìä:\n"
        f"–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ üìö: {n_support}\n"
        f"–ü—Ä–∏–º–µ—Ä—ã:\n{supporting_lines if supporting_lines else '–ù–µ—Ç –¥—Ä—É–≥–∏—Ö supporting-—Å—Ç–∞—Ç–µ–π'}"
        f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ‚úÖ: {confidence}\n"
        f"–ö–æ–Ω—Å–µ–Ω—Å—É—Å ü§ù: {consensus}\n"
        f"–¢–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞ üî¨: PubMed\n"
        f"–ö–∞—á–µ—Å—Ç–≤–æ ‚≠ê: –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ—Ü–µ–Ω–∑–∏—Ä—É–µ–º—ã–µ –∏–∑–¥–∞–Ω–∏—è"
    )
    await update.message.reply_text(answer)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø LongevityBionixBot.\n"
        "–Ø –∏—â—É –ª—É—á—à–∏–µ –Ω–∞—É—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ –ø–æ –ø—Ä–æ–¥–ª–µ–Ω–∏—é –∂–∏–∑–Ω–∏ –∏ –∑–∞–º–µ–¥–ª–µ–Ω–∏—é —Å—Ç–∞—Ä–µ–Ω–∏—è —É –ª—é–¥–µ–π.\n"
        "–í–≤–µ–¥–∏ /task, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –¥–Ω—è!"
    )

def run_bot():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("task", task))
    import asyncio
    asyncio.run(app.run_polling())

if __name__ == "__main__":
    run_bot()
